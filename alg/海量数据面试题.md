### 海量数据面试题

- 给定a,b两个文件，各存放50亿个url,每个url占64B,内存限制是4G，让你找出a,b文件共同的url？

1. 布隆过滤器，有一定的错误率，64B/8=8B=64bits,4GB=4x10^9,要将50x10^9x8B=400x10^9B=400GB映射到4GB中，%100，怎么映射？

2. 50亿x64B~50Gx64B=320GB>4GB,不能完全加载进去，所以采用分而治之的办法，遍历文件a,对每个url%1000,放到1000个小文件中(a1)，这样每个小文件约为300MB,遍历文件b,b%1000,存到1000个小文件中（b1）,检索a1,b1中相同的url,循环操作1000次即可； 对url需要用个hash函数然后在%1000。


- 有10个文件，每个文件1G,每个文件的每一行存放的都是用户的query,每个文件的query可能重复，要求按照query的频度排序。

1. hash处理%10，放到10个文件中，这样重复的一定在同一个文件中，然后对每个文件，建立hash函数，统计每个元素的频次，通过堆排序得到一个有序文件，最后对这10个文件进行归并，根据内存情况，若较小，可通过hash划分成可以满足的小文件，进行堆排序，然后将这些小文件合并

2. 一般query总量悠闲，只是重复的较多，所以可以一次性加载到内存中，可以用前缀树统计query出现的次数，然后通过堆排序，完成输出；若还是较大，可以划分成几个文件，同样的操作，得到每个文件中的有序query,然后进行归并。

3. map-reduce


- 有⼀个1G⼤⼩的⼀个⽂件，⾥⾯每⼀⾏是⼀个词，词的⼤⼩不超过16字节，内存限制⼤⼩是1M。返回频数最⾼的100个词

这个1G是占用空间，不是单词个数，所以1G/1M=1000,划分成5000个小文件，这样每个文件200kB<1MB，即堆每个单词计算hash%5000，分配到5000个小文件中，相同的词在同一个文件里；然后对每个小文件通过hash_map进行计算频次，建立100大小的堆，对小文件进行堆排序，得到局部频次最高的100个词，每个小文件同样的操作，进行归并操作，选择出频次最高的100个词。


- 海量⽇志数据，提取出某⽇访问百度次数最多的那个IP

1. 首先将该天访问百度的日志中的IP提出取来，逐个写入到一个大文件中，IP,4B,最多有2^32个，即不重复最大为4Gx4B=16GB,通过hash%100得到100个小文件，对小文件通过hash_map统计频次，占用160MB，直接找到频次最多的那个IP；对每个小文件进行相同操作，最后从这100个IP中选择频次最高的那个IP

- 在2.5亿个整数中找出不重复的整数，内存不足以容纳这2.5亿个整数

- 海量数据分布在100台电脑中，想个办法高效统计处这批数据的TOP10


- 怎么在海量数据中找出重复次数最多的一个

- 上千万或上亿数据（有重复），统计其出现次数最多的前N个数据


- 1000万字符串，其中有些是重复的，需要把重复的全部去掉，保留没有重复的字符串，怎么设计和实现？


- 一个文本文件，大约有一万行，每行一个词，要求统计出其中最频繁出现的前10个词，请给出思想，给出时间复杂度分析。


- 一个文本文件，找出前10个经常出现的词，但这次文件比较长，说是上亿行或十亿行，总之无法一次读入内存，问最优解


- 100w个数中找出最大的100个数


- 寻找热门查询

搜索引擎会通过⽇志⽂件把⽤户每次检索使⽤的所有检索串都记录下来，每个查询串的
⻓度为1-255字节。假设⽬前有⼀千万个记录，这些查询串的重复读⽐较⾼，虽然总数是
1千万，但是如果去除重复和，不超过3百万个。⼀个查询串的重复度越⾼，说明查询它
的⽤户越多，也就越热⻔。请你统计最热⻔的10个查询串，要求使⽤的内存不能超过
1G。
(1)	请描述你解决这个问题的思路；
(2)	请给出主要的处理流程，算法，以及算法的复杂度。


- ⼀共有N个机器，每个机器上有N个数。每个机器最多存O(N)个数并对它们操作。如
何找到N^2个数中的中数
