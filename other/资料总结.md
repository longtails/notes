
#### 数据结构

Hash表：常见hash函数，直接定址法，除留余数法，数字分析法:   
**直接定址法：** H(key)=a*key+b,计算简单，不会产生冲突，适合关键字连续分布的，否则空位较多，空间浪费   
**除留余数法：** H(key)=key%p，表长m，选择最接近或等于m的质数p,这种方法最简单，最常用，关键是选好p,使得每个关键字通过该函数转换后都能等概率的映射到散列空间上任一地址，从而尽可能减少冲突的可能性   
**数字分析法:** 关键字是r进制数，r个数码在各位上，出现的频率不一定相同，应选择数码分布相对均匀的若干位作为散列地址，这种方法只适合已知的关键字集合。

***处理冲突:****   
1. 拉链法，对相同地址的关键字，则用线性链表存储，这种方法适合经常进行插入和删除的情况  
2. 开发定址法，空闲地址向非同义词开发，H=(H(key)+di)%m,引入di增量序列；但开放地址有个问题，就是不能随便物理删除，需要删除，可以做个删除标记，表示逻辑删除，带来的结果是，整个表很大，但实际上很多空间没有用到，所以需要定期维护散列表。这个增量di的选择有四种常用方法：
   1. 线性探测法，di=1,2,3,...,m-1,即当冲突时，顺序查找下一个单元，直到全表，该方法容易造成数据聚集，降低查找效率
   2. 平方探测法，di=1,-1,2^2,-2^2,3^2,-3^2,...,k^2,-k^2,k<=m/2,m必须是一个可以表示成4k+3的质数，这是一种比较好的处理冲突方法，可以避免数据堆积，缺点是不能探测到Hash表上的所有单元，但至少能探测一半。
   3. 再散列法，di=i*hash2(key),利用第二个散列函数计算该关键字的地址增量，最多经过m-1测探测，会遍历表中所有位置，回到H0位置  


装填因子a=表中记录数n/散列表长度m，表示装满程度，Hash表的查找效率与散列函数，处理冲突的方法和装填因子。hash表的平均查找长度不单独取决于n和m，而是a。

---

B数，红黑树

---
外部排序：

---

#### 计算机网络

网络分层：


Socket:

socket起源于unix,在unix一切皆文件的思想下，socket是一种“打开-读/写-关闭”模式的实现。   

tcp socket： 
tcp socket 是标示了一台主机的进程，是tcp连接中一端的实例。socket不是连接，只是表示了其中一端。由IP和port构成。    
tcp 连接： 
tcp连接由两台主机上的进程的socket连接构成。

socket通信流程
![](https://images0.cnblogs.com/blog/349217/201312/05232335-fb19fc7527e944d4845ef40831da4ec2.png)

server:
1. 创建socket文件，
2. bind,绑定socket和端口号，
3. listen监听该端口, 
4. 当客户端发来链接请求，服务端accept接收请求, 期间阻塞,发送SYN,ACK
5. 之后用recv从socket中读取字符, 
6. 最后关闭socket

client:
1. 创建socket文件
2. connect链接指定服务器的端口，这时发送SYN
3. send向socket写入信息，发送ACK
4. 最后close关闭

internet domain socket,用于不同主机之间进程通信：  
通过lsof查看打开的文件，可以看到server 监听的文件名 \*:port ，建立链接后，可以看到client ip:port->server ip:port 的链接文件
lsof -i:port
![](https://img-blog.csdn.net/20170911091243160?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvYmRzczU4/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

Unix domain socket，用于本机进程通信，使用方式和internet差不多，只是type不同，使用unix domain时，需要指定socket文件名，创建socket文件。

AF_INET和AF_UNIX的区别


ARP协议:
完成ip到mac地址的映射，主机上存放一个IP-MAC地址映射表，ARP表，并通过ARP协议动态维护此表。   
**ARP协议工作在网络层**。工作原理：主机A向本局域网上的某个主机B发送IP数据报时，先查看ARP告诉缓存中是否有主机B的IP地址，若有，则可查出对应的硬件地址，再将MAC地址写入MAC帧，然后通过局域网发出去；若没有，则先通过广播ARP请求分组(MAC帧的目的地址为FF-FF-FF-FF-FF-FF),在获得目标主机的ARP响应分组后，将目标主机的硬件与IP的映射关系写入ARP缓存表中，然后按此硬件地址写入MAC帧，发送出去。   
注意，ARP解决的是一个局域网上的主机或路由器的IP-MAC映射问题，若两个主机不在一个局域网上，则要通过ARP协议找到本局域网上路由器的硬件地址，将分组发送给该路由器，然后有路由器转发到下一个网络。

DHCP动态主机配置协议，使计算机动态加入新的网络，并动态分配IP地址，DHCP是应用层协议，基于UDP。主机启动时，通过广播发现报文，然后DHCP服务分配IP并作响应。   
ICMP:为提高IP数据报文交付成功的机会，ICMP协议来报告差错和异常情况，ICMP实际也是IP分组，只不过ICMMP被作为IP分组的数组字段，ICMP为网络层。

ICMP两个常见应用，PING和Tracerroute：    
PING利用的是ICMP回送请求和回答报文，工作在应用层，它直接使用网络层的ICMP协议，没有使用传输层的TCP/UDP;   
Tracerroute使用ICMP不可达差错报文，发送修改IP报文的最大跳数，工作在网络层。

NAT:解决IPv4地址不够用的问题，路由器上安装NAT软件，通过NAT转换地址将本地地址转换层公网ip，NAT会查看和转换传输层的端口。  
私有IP，不能上公网，因为公网上的路由直接对其私有IP。  

反向代理？

#### TCP三次握手、四次挥手：


#### tcp和udp的区别?
1. TCP面向连接(如打电话要先拨号建立连接);UDP是无连接的，即发送数据之前 不需要建立连接   
2. TCP提供可靠的服务。也就是说，通过TCP连接传送的数据，无差错，不丢失， 不重复，且按序到达;UDP尽最大努力交付，即不保证可靠交付   
3. TCP面向字节流，实际上是TCP把数据看成一连串无结构的字节流;UDP是面向 报文的，UDP没有拥塞控制，因此网络出现拥塞不会使源主机的发送速率降低   
4. 每一条TCP连接只能是点到点的;UDP支持一对一，一对多，多对一和多对多的 交互通信   
5. TCP首部开销20字节;UDP的首部开销小，只有8个字节   
6. TCP的逻辑通信信道是全双工的可靠信道，UDP则是不可靠信道   

#### DNS域名解析过程：
层次域名空间，一个ip可以对应多个域名；
域名服务器，C/S模型，有四种不同类型的域名服务器：  
**本地域名服务器**:每个ISP，学校，部门都可以拥有一个自己的本地域名服务器,本机IP配置时其DNS指向本地域名服务器；  
**根域名服务器**:Internet上有十几个根域名服务器，大部分在北美，该服务器是最重要的域名服务器,当本地域名服务器无法解析某个DNS请求时，此DNS会被转发到一个根域名服务器进行查询，根域名服务器管理顶级域名(如.com)。当根域名也没查到，它根据顶级域名信息告诉下属的某个本地域名服务器应当去哪个顶级域名服务器查询。  
**顶级域名服务器**： 负责管理在顶级域名服务器注册的所有二级域名。当收到DNS查询请求时，给出相应回答，若未能解析到，则返回下一级的域名服务器地址。   
**授权域名服务器**：每个主机都必须在授权域名服务器处登记。为了可靠，每个主机最好至少有两个授权域名服务器。许多域名服务器同时充当本地域名服务器和授权域名服务器。授权域名服务器总是能够将其管辖的主机名转换为该主机的IP地址。  

域名->IP：正向解析；IP->域名：反向解析  
解析时，本地DNS客户端向本地域名服务器发送UDP数据请求报文，具体解析过程：   
递归查询： 主机->本地域名服务器-->根域名服务器-->顶级域名服务器-->授权域名服务器-->顶级-->根-->本地->主机  
迭代查询：主机->本地域名<-->根域名；本地<-->顶级；本地<-->授权；本地->主机

理解，其实最高层次的是根域名服务器，然后通过层次管理的方式，依此降级管理；授权域名服务器，就是最低的域名管理的服务器，记录了主机IP对应的完整域名；而本地域名服务器，更像一个记录的缓存表，同样根也缓存了部分域名。

再结合域名的层次划分：在主机缓存中未查到；请求本地域名服务器（主机和本地域名服务器都只是缓存记录，而不是管理着，都需要向管理者请求）；本地缓存中未命中，递归到根域名（根是管理）；根缓存未命中，这时发挥它的管理作用，根据记录的顶级域名服务器地址，根向顶级服务器请求；顶级还未命中，那直接向在顶级服务器中记录的授权服务器(顶级下的子服务器)，最后一定能否在授权服务器中查询到，否则不存在，最后迭代返回。   
迭代的方式，是本地域名服务器分别和根、顶级、授权，依次请求，后续的服务器的IP有前一个服务器提供。这里体会到本地域名服务器的作用，因为一般主机没权限，同时加了一层，能够降低域名管理者的压力。





浏览器输入URL后，发生什么？

0. 解析URL，地址和参数   
1. 检查HSTS列表，决定使用HTTPS还是HTTP 
2. 浏览器通过DNS查找域名的IP地址
3. 依次查浏览器中缓存的DNS记录->系统中的DNS记录->请求域名解析服务器(递归和迭代两种方式)
4. ARP地址解析，解析到目标IP的MAC地址，或者局域网的路由器MAC
4. 浏览器与服务器建立TCP连接
5. TLS握手，使用HTTP协议请求发送数据（apached）
5. 发出Get命令，获取首页
6. 最后，释放TCP连接
7. 渲染首页所有内容

---
#### HTTP/HTTPS:   
1. 长连接、短连接
2. https建立连接过程

HTTPS过程：
1. client->server:发送hello消息，告知其支持的加密算法等信息，随机数
2. server->client:发送hello消息，确定选择的加密算法，随机数2,发送自己的证书,编码改变通知，即应用上述参数，如果需要，对方的证书会发送请求，最后发送hello done
3. client->server：生成第三个随机数，并利用三个随机数生成对称密钥，并用server公钥加密，以及之前参数的hash值并用对称密钥加密
4. server->client: 用私钥解出对称密钥，并用其解密参数的hash值，和本地生成的hash最对应，验证结果，最后发送加密的参数的hash值供客户端验证
5. 双方验证通过后，进入通信阶段。

#### TLS:
基本过程
1. 客户端向服务器端索要并验证公钥
2. 双方协商生成"对话密钥"
3. 双方采用"对话密钥"进行加密通信
----
四次握手阶段（这里是单向认证过程）：  
hello消息阶段   
客户端发送ClientHello请求：
1. TLS版本
2. 客户端生成的伪随机数，用于生成对称密钥
3. 支持的加密算法
4. 支持的压缩算法

服务器响应ServerHello： 
1. 确认使用的TLS版本
2. 一个服务器生成的伪随机数，用于生成对称密钥
3. 确定使用的加密算法
4. 确定使用的压缩算法
5. 服务器证书（包含公钥）

证书校验部分   
客户端响应，在验证服务器证书之后：
1. 一个伪随机数，**用服务器公钥加密后传输**，防止被窃听
2. 编码改变通知，表示随后用双方协定的加密方法和密钥发送
3. 客户端握手结束，客户端的握手阶段结束，这一项同时也是前面发送的所有内容的hash值，用于供服务器校验    

    这时，客户端已经有生成对称密钥的三个随机数了，这里会把之前通信参数的hash值与其他相关信息生成一段数据，并用对称密钥加密，发送给服务器用于数据和握手验证，同时也会验证服务器发送来的验证消息，确定密钥和数据的正确性。

服务器响应：
1. 编码改变通知，表示之后用协定的加密算法和密钥
2. 服务器握手结束，表示服务器的握手阶段结束，这一项同时也是前面发送的所有内容的hash值，用来供客户端校验
（服务器用私钥解密加密的随机数，并生成对称密钥，计算之前通信参数的hash值，然后解密客户端发送的加密验证消息，验证数据和密钥的正确性，验证通过后，发送编码改变通知，同时用密钥加密生成的hash值发送到客户端，供其验证）    
    
    双方通过握手获得的是三个随机数和选择的加密算法，生成对话密钥，加密接下来的整个对话过程
握手过程使用明文通信，对话阶段加密。     

以上存在三个伪随机数又成为pre-master-key，主要是对称密钥生成需要pre master secret,如果知道pre master secret很容易确定密钥，并且TLS协议中的证书是静态的；所以这个pre master secret一般是个随机数，这里用三个伪随机数一同生成密钥是因为ssl不信任每个主机能产生完全随机的随机数，随机性就十分接近随机了。   



详细过程：
1. C->S,发送一个Client hello消息：消息中同时包括TLS版本，可用加密算法和压缩算法
2. S->C,返回一个Server hello消息：消息中包含了服务端的TLS版本，服务器选择的加密和压缩算法，服务器公开的证书，证书中包含了公钥;客户端会使用这个公钥加密接下来的握手过程，直到协商产生一个新的对称密钥
3. C->S,发送加密的伪随机数：客户端根据自己信任的CA列表，验证服务器的证书是否有效；若有效，客户端生成一串伪随机数，使用服务器的公钥加密它，发送到服务器上
4. S->C,发送生成的对称密钥：服务器用私钥解密客户端发来的伪随机数，并用该数生成一个对称加密的密钥
5. C->S,客户端发送一个Finished消息给服务器，和用对称密钥这次通讯的一个哈希值
6. S->C,服务端生成自己的哈希值，然后解密客户端发来的消息，检查这两个值是否对应，如果对应就向客户端发送Finished消息，并使用对称密钥加密此次消息
7. 接下来，双方通讯整个TLS会话都会使用对称密钥进行加密，传输应用层(http)内容


HTTPS (HTTP over TLS,即TCP上时TLS安全层，TLS上才是应用层HTTP)

---

#### 什么叫桥接？

桥接是指依据OSI网络模型的**链路层**的地址，对**网络数据包进行转发的过程**，工作 在OSI的第二层；一般的交换机，网桥就有桥接作用。


##### tcp三次握手和四次挥手流程示意图？在黑板上画出

#### 客户端在建立异常中发现很多connect reset by peer,你觉得问题出在哪？
全连接队列、半连接队列溢出
半连接队列的大小取决于：max(64,  /proc/sys/net/ipv4/tcp_max_syn_backlog)，不同版本的os会有些差异。   
全连接队列的大小取决于：min(backlog, somaxconn) . backlog是在socket创建的时候传入的，somaxconn是一个os级别的系统参数。


---

### 操作系统

程序的装入和链接：

#### 一个简单的c程序hello world，从启动，到输出的全过程：

1. 预处理、编译、汇编、链接，生成目标文件，a.out
2. ./a.out 启动启动程序，shell更具文件名和环境变量去读取磁盘中的二进制文件
3. 根据目标文件的ELF文件头，获取一些必须要的信息比如机器位数、程序入口地址，处理执行二进制文件，在终端输出hello world

链接：重定位的问题，需要将外部引入的信息，比如外部函数，这些函数、变量，并没有在目标文件内，在链接时，完成地址的填充；

装载：把程序加载到物理内存中，程序使用虚拟存储机制，需要将虚拟地址转化为物理地址，这里的地址转化由操作系统利用地址转换机构完成,linux逻辑存储上采用页表管理的方式，64位虚拟地址使用48位物理地址，划分为4x9+12,四级页表+页内偏移的方式，
运行时动态重定位获取物理地址，指令代码通过基址+限址的方式，PC指令计数器，执行执行。

运行时库，C运行时库除了给我们提供必要的库函数调用（如memcpy、printf、malloc等）之外，它提供的另一个最重要的功能是为应用程序添加启动函数；C运行时库启动函数的主要功能为进行程序的初始化，对全局变量进行赋初值，加载用户程序的入口函数。

程序的起始物理地址装载到基址寄存器中，程序的长度装载到界限寄存器中，逻辑地址+基址

逻辑地址，线性地址，物理地址：   
逻辑地址（Logical Address） 是指由程式产生的和段相关的偏移地址部分；。只有在Intel实模式下，逻辑地址才和物理地址相等（因为实模式没有分段或分页机制,Cpu不进行自动地址转换）；逻辑也就是在Intel保护模式下程式执行代码段限长内的偏移地址（假定代码段、数据段如果完全相同）。
线性地址（Linear Address）也叫虚拟地址(virtual address)是逻辑地址到物理地址变换之间的中间层。
物理地址（Physical Address） 是指出目前CPU外部地址总线上的寻址物理内存的地址信号，是地址变换的最终结果地址。如果启用了分页机制，那么线性地址会使用页目录和页表中的项变换成物理地址。如果没有启用分页机制，那么线性地址就直接成为物理地址了。

页表目录寄存器：每个进程都有自己的页表目录寄存器，

逻辑地址，先转到线性地址，线性地址，通过页表找到对应的物理地址；若没有启动页表，则线性地址直接就是物理地址。

shell是操作系统的外壳，为用户提供os的接口，.\a.out的将字符串发送到标准输出上，系统则通过gui显示的屏幕上；另外还可以重定向操作，将程序输出重定向到文件中一样。


linux文件描述符 0,1,2：stdin，stdout和stderr（默认分别是键盘、显示器、显示器），shell通过stdin文件描述符从键盘接收输入，并在键入时处理每个字符；stdout文件描述符引用shell的标准输出，在终端接口标准输出是终端显示器，shell的所有输出都定向到监视器。前台程序输出定向到标准输出，即显示器上，后台程序，定向到文件上。



#### linux最大分配几级页表：


地址：逻辑地址 --（段表）--> 线性地址 --（页表)--> 物理地址   
页表的启用，体现在线性地址上，若启用页表，要完成线性地址和物理地址的转化；逻辑地址到线性地址，就是取后48位即可。   



先看下系统的页表大小：
```bash
root@hw2:~# getconf PAGE_SIZE
4096
```

linux的页表分配是根据cpu来设计的，不同平台(cpu)分页不同,这里考虑x86平台:  

平台|linux页表|地址分配 |可表示大小
---|---|---|---
x86 |二级页表|10,10,12=32|4GB
x86_amd| 四级页表|9,9,9,9,12=48(线性地址)|256TB


intel 48线性地址划分：
![intel linear address](https://ask.qcloudimg.com/http-save/yehe-2966179/psg8p61gvr.png?imageView2/2/w/1620)
页表目录寄存器：每个进程都有自己的页表目录寄存器。

对应是：
单元|描述
---|---
页全局目录 | Page Global Directory
页上级目录 | Page Upper Directory
页中间目录 | Page Middle Directory
页表 | Page Table
页内偏移|Page Offset



linux把计算机分成独立层/依赖层两个层次，对于页面的映射和管理也是；linux从最初的2级页表，到3级页表(x86支持物理地址扩展)，再到4级页表(64cpu)。


总结来说：页表大小位4KB,所以页内地址需要12位，虚拟地址64位，需要8B,那一页最多存储4KB/8B=2^9,即一级页表占用9位，intel x86_64平台使用48位物理地址，剩余的48-32=9x4可以构成四级页表，48位物理地址可以表示多大的内存空间，2^48B=256TB,此外，x86系列是向后兼容的，为什么是4级页表？因为linux一路从2级页表、3级页表，再到当前的4级页表，满足当前需要，若未来那天不够用了，当然会扩展出更大的。

参考：
1. [Linux分页机制之概述--Linux内存管理(六)](https://cloud.tencent.com/developer/article/1373361)
2. [内核必须懂(七): Linux四级页表(x64)](https://cloud.tencent.com/developer/article/1421792)



---

#### select、poll、epoll详解

在网络通信中，select、poll、epoll主要用于提供IO多路复用的解决方案，IO多路服用是指内核一旦发现进程指定的一个或者多个IO条件准备读取，他就通知该进程，IO复用的是一个线程。属于同步IO模型。

select,i/o服用模型的关键点在于fd_set,这是一个整型数组，数组的每个成员都表示一个文件描述符。在调用select的时候，用户空间将要检测的各种事件的文件描述符以fd_set整型数组的形式传递给内核空间。
内核空间通过轮询监听这个集合中是否与坚定时间发生，如果某个描述符上述对应的监听实践，则设置为1，跳出阻塞。
```c
int select(int maxfdp1,fd_set *readset,fd_set *writeset,fd_set *exceptset,const struct timeval *timeout)
```

不足：
1. 没必要在每次执行select时，都重新向内核传递表示监听的描述符的整型数组，因为这个一般时相对稳定的；
2. 监听的个数有限
3. 使用遍历轮询的监听方式，需要一定的开销

poll,实现原理和select差不多，只是对监听描述符集的描述上有所差异,poll使用struct pollfd结构体描述要监听的描述符集,没有了最大数量的限制。从性能或者系统开销上看poll和select的差别不大 ，目前使用select模型的服务器比较多，poll使用并不广泛,和select一样同样存在将大量维纳描述符复制到内核空间，而不论这些文件描述符是否就绪，所以它的开销会随着文件描述符的增加而线性增加。
```c
struct pollfd {
int fd;         /* 文件描述符 */
short events;         /* 等待的事件 */
short revents;       /* 实际发生了的事件 */
} ; 
int poll ( struct pollfd * fds, unsigned int nfds, int timeout);
```


epoll,没有文件描述符数量限制，使用一个文件描述符管理多个描述符，将用户关系的文件描述符的事件存放到内核的一个事件表中，这样用户空间和内核空间只需复制一次，并使用一组函数来实现i/o复用：
```c
//创建一个额外的文件描述符，用于表示服务器要监听的事件在内核中对应的事件表，来管理其他文件描述符
int epoll_create(in size)
//用作操作参数epfd(由上个函数创建)对应的内核事件表，如向事件表中注册、修改、删除事件
int epoll_ctl(int epfd,int op,int fd,struct epoll_event *event)
//主要函数，用于在超时时间内阻塞监听注册的事件
int epoll_wait(int epfd,struct epoll_event *events,int maxevents,int timeout)
```

原理，epoll_ctl将要监听的各个描述符的事件传递给内核共建，并为每个描述符指定回调函数，当描述符上有事件发生，会调用回调函数，将文件描述符添加到一个就绪队列中去。

epoll_wait用于阻塞监听各个文件描述符是否有监听的事件发生，因为epoll_ctl中为每个要监听的文件描述符指定了回调函数，因此epoll_wait就不需要轮询检测各个文件描述符，只要判断就绪队列是否为空即可。

？怎么就不用轮询了

对比：
1. select每次调用都重新向内核传递监听的描述符，浪费了一些开销，而epoll只需要使用epoll_ctl左一次处理，之后epoll_wait阻塞监听时不再需要向内核空间传递要监听的描述符
2. epoll模型并非像select使用整型数组来哔哦啊是监听的描述符集，因而能够监听的文件描述符比较大
3. select在阻塞监听时，需要轮训每个监听的文件描述符，而epoll只需判断就绪队列是否为空，在没有监听事件发生时，epoll可以更早的让出cpu。

[select、poll、epoll详解](https://blog.csdn.net/windeal3203/article/details/52055436)
[select,poll,epoll三种IO机制对比介绍](https://blog.csdn.net/zymill/article/details/79998593)


#### 什么叫虚拟内存？
虚拟内存是计算机系统内存管理的一种技术。它使得应用程序认为它拥有连续的 可用的内存（一个连续完整的地址空间），而实际上，它通常是被分隔成多个物理内 存碎片，还有部分暂时存储在外部磁盘存储器上，在需要时进行数据交换。

也就是，在分页启动后，才启动虚拟地址，x86保护模式程序运行在虚拟地址下，实模式程序运行在实地址下。


#### Linux什么命令可以查看cpu和内存？怎么查看每个核的cpu呢？
top命令，按1可以查看各个核的信息

#### 给一个PID=100你觉得它是后台程序还是前台程序？

进程号0-299保留给daemon进程

#### 怎么查看一个端口的TCP连接情况？

netstat

#### Docker的网络模式有哪几种？

bridge网络
host网络
none网络
container模式

#### 介绍一下Tcpdump？

tcpdump网络数据包截获分析工具。支持针对网络层、协议、主机、网络或端口 的过滤。并提供and、or、not等逻辑语句帮助去除无用的信息。


#### 什么叫大端和小端？

1.Little-Endian（小端）就是低位字节排放在内存的低地址端，高位字节排放在内存的高地址端    
2.Big-Endian（大端）就是高位字节排放在内存的低地址端，低位字节排放在内存的高地址端。   
像64bits,需要8B才能构成一个int,那这8个怎么放就是大端和小端模式。   
小端模式：强制转换数据不需要调整字节内容   
大端模式：符号位的判定固定为第一个字节，容易判断正负
使用场景   
一般操作系统都是小端的，而通信协议是大端的


#### 介绍下 docker 底层原理


#### 介绍些僵尸进程和孤儿进程的区别, 怎么产生的, 怎么避免?

在操作系统领域中，孤儿进程指的是在其父进程执行完成或被终止 后仍继续运行的一类进程。

在类UNIX系统中，僵尸进程是指完成执行（通过 exit 系统调用，或运行时发生致命错误或收到终止信号所致）但在操作系统的进程表中仍然有一个表项（进程控制块PCB），处于"终止状态 "的进程。

1、一般情况下，子进程是由父进程创建，而子进程和父进程的退出是无顺序的，两者之间都不知道谁先退出。正常情况下父进程先结束会调用 wait 或者 waitpid 函数等待子进程完成再退出，而一旦父进程不等待直接退出，则剩下的子进程会被init(pid=1)进程接收，成会孤儿进程。（进程树中除了init都会有父进程）。
2、如果子进程先退出了，父进程还未结束并且没有调用 wait 或者 waitpid 函数获取子进程的状态信息，则子进程残留的状态信息（ task_struct 结构和少量资源信息）会变成僵尸进程。
3、守护进程（ daemon) 是指在后台运行，没有控制终端与之相连的进程。它独立于控制终端，通常周期性地执行某种任务 。 守护进程脱离于终端是为了避免进程在执行过程中的信息在任何终端上显示并且进程也不会被任何终端所产生的终端信息所打断 。

危害：   
孤儿进程结束后会被 init 进程善后，并没有危害，而僵尸进程则会一直占着进程号，操作系统的进程数量有限则会受影响。    
解决：   
一般僵尸进程的产生都是因为父进程的原因，则可以通过 kill 父进程解决，这时候僵尸进程就变成了孤儿进程，被 init 进程接收

#### CPU 使用率和 CPU 负载有什么区别?


cpu使用率反映的是当前cpu的繁忙程度，忽高忽低的原因在于占用cpu处理时间的进程可能处于io等待状态但却还未释放进入wait。

平均负载（load average）是指某段时间内占用cpu时间的进程和等待cpu时间的进程数，这里等待cpu时间的进程是指等待被唤醒的进程，不包括处于wait状态进程。

平均负载是指上一分钟同时处于就绪状态的平均进程数，Load Average的值应该小于CPU个数X核数X0.7，Load Average会有3个状态平均值，分别是1分钟、5分钟和15分钟平均Load。
 
---

逻辑地址和物理地址的转化：

分页、分段、

虚拟内存置换、页面置换算法：

linux文件

死锁、信号量

自旋锁和互斥锁一样是用来保护共享资源的，不同点在于资源被加锁时，互斥锁为让申请者睡眠，而自旋锁是通过循环检查的方式，所以自旋锁是一种较为低级的原始的锁，忙等，但避免了上下文的调度开销，因此对于只会阻塞很短时间的场景是有效的；整体上，耗费CPU时间较长，可能造成死锁，此外自旋锁不能递归调用。

[面试必备之深入理解自旋锁](https://zhuanlan.zhihu.com/p/40729293)


---
数据库
---
秒杀
---
架构
